--- 
layout: post 
title: 译“差分隐私的算法基础”
subtitle: 第二章/第二节
date: 2018-05-26
author: ShixiongMarryMe 
header-img: img/post-bg-DPTranslation5.jpg 
catalog: true
tags:
    - DP 
    - Translation
--- 
>The Algorithmic Foundations of Differential Privacy  
>@Cynthia Dwork
>@Aaron Roth

（背景图片来自网络，侵删歉）

## 2.2 定义隐私数据分析

在数据分析的背景下定义隐私的一种自然的方法是，要求分析人员在分析完成后（除了在分析开始前知道的）不再了解更多关于数据集中的任何个人的信息。同样很自然地形式化这样一个目标，即要求对手对一个隔日个人(即访问数据库之前和之后)的前后观点不应该“差别太大”，或者对手在访问数据库后不应该对任何个人改变“太多”的看法。然而，如果数据库能够教任何东西的话，那么隐私的概念也就无从谈起。举个例子，假设对手先前的(错误的)观点是“每个人都有2只左脚”。在访问统计数据库后，得知几乎每个人都有一只左脚和一只右脚。那么无论被给出的访问者是否有两只左脚，对手现在对“每个人都有2只左脚”这个事情会有着截然不同的看法。

无论是对前后观点的要求，或者是对“什么都没学到”的要求，直观上而言，这些定义隐私的方法是：如果没有学到关于某个个体的任何信息，那么这个个体将不会受到分析的伤害。 然而“吸烟导致癌症”的例子表明这种直觉是有缺陷的; 罪魁祸首是辅助信息（例如 X先生抽烟）。

用于定义隐私的“什么都学不到”方法让人想起密码系统的语义安全性。粗略地来说，语义安全表示无法从密文中得到明文(即未经加密的消息)的任何信息。也就是说，在看到密文之后知道有关明文的任何信息在查看密文之前是已知的。_（That is, anything known about the plaintext after seeing the ciphertext was known before seeing the ciphertext.附原句，此句不会翻译 ）_@ShixiongMarryMe因此，如果有辅助信息说明密文是“狗”或“猫”的加密，那么密文就不会进一步泄露关于“狗”或“猫”中的哪一个已被加密的信息。在形式上，这是通过比较窃听者猜测哪个“狗”和“猫”已被加密的能力与所谓的对手模拟器猜测同样事情的能力建模的，该模拟器具有辅助信息但不能访问密文。如果对于每一个窃听的对手以及所有辅助信息(敌手和模拟器都是私密的)，那么攻击者模拟器具有和窃听者基本相同的猜测几率，这样系统就具有语义安全性。当然，要使系统有用，合法的接收方必须能够正确解密该消息;否则语义安全也就无法大展身手了。

我们知道，在标准的计算假设下，语义上安全的密码系统是存在的，那么我们为什么不能构建语义上安全的隐私数据库机制使得其在保持单个行秘密的同时产生查询答案？

首先，这个类比并不完美。在语义安全的密码系统中，存在着这样的三方：消息发送方(加密明文消息)，消息接收方(解密密文消息)和窃听方（因无法学习任何她在发送之前不知道的明文而感到沮丧）。 相比之下，在私人数据分析的设置中，只有两方：策展人，他们负责运行隐私机制的（类似于发件人）和数据分析人员，他们接收对查询的信息性回复(如消息接收方)，还试图找出对个人隐私损害的信息（如窃听者）。由于合法的接收方与窥探的对手是同一方，因此与加密类似是有缺陷的@师兄嫁我，即拒绝向对手提供所有信息意味着拒绝向数据分析员提供所有信息。

其次，与加密方案一样，我们需要隐私机制有用，这意味着它会教会分析师以前不知道的事情。这种教学对敌手模拟器不可用，也就是说，没有一个模拟器可以“预测”分析师已经学到了什么。因此，我们可以将数据库视为随机（不可预知）位的弱来源，从中我们可以提取一些非常高质量的随机性用作随机填充（random pad此处不会翻译，姑且译为随机填充）。这可被用于将秘密消息添加到随机值的加密技术（“随机填充”）中，以产生理论上的隐藏秘密信息的字符串。只有知道随机填充的人才能知道这个秘密，任何对这个填充一无所知的一方都不会了解这个秘密，不管他或她的计算能力如何。鉴于对数据库的访问，分析人员可以学习随机填充，但敌手模拟器（无法访问数据库）根本没有获知有关填充的信息@师兄嫁我。因此，作为辅助信息，使用随机填充对秘密进行加密，分析师可以破解该秘密，但攻击者模拟器根本不了解秘密。这在对手/分析师学习秘密的能力与对手模拟器做同样事情的能力之间产生巨大的差距，从而消除任何类似语义安全的全部希望。

吸烟导致癌症的例子和语义安全希望的障碍都是辅助信息。很显然，即使在“合理的”辅助知识背景下，隐私保证也必须具有意义，但将合理性从任意辅助知识中分离出去是有问题的。例如，使用政府数据库的分析师可能是一家主要搜索引擎公司的员工，那么什么是对提供给这样的人可用的辅助知识信息的“合理的”假设？

__*欢迎纠正不妥之处，转载敬请注明出处*__
