--- 
layout: post
title: Translate "The Algorithmic Foundations of Differential Privacy"
description: Chapter2/Section3 
date: 2018-05-27 
author: ShixiongMarryMe  
link: 
comments: false
photos:
    -
categories:
    - Differential Privacy
tags: 
    - Translation
--- 

>@Cynthia Dwork
>
>@Aaron Roth

## 2.3 形式化差分隐私

我们将从差分隐私的技术定义开始，继而对其进行解释。差分隐私将通过一个过程来提供隐私保护。特别是它会引入随机性。随机过程关于隐私的一个早期例子是随机反应，这是一种在社会科学中开发的技术，用于收集关于尴尬或非法行为的统计信息，通过拥有特性*P*来捕获。研究的参与者被告知要报告他们是否拥有如下的特性*P*：

1.翻转一枚硬币。

2.如果是**尾巴**（正面），然后如实回复。

3.如果是**头**（背面），然后翻转第二个硬币，如果是头，则回答“是”，如果是尾，则回答“否”。

 “隐私”来自对任何结果的合理否认；特别是如果把具有特性P等价于从事非法行为的话，即便是一个肯定的回答也没有入罪，因为不管被访者是否实际上具有特性P，这个答案的出现概率至少为1/4。准确性来自于对噪音产生程序的理解(所引入的虚假的“是”和“否”答案来自随机化)：预期的“是”答案的数量是(1/4)\*(没有特性P的参与者的数量)+(3/4)\*(有特性P的参与者数量)。因此，如果小p是具有属性P的参与者的真实数量（ true fraction不会翻译，给出原文），则预期的“是”答案的数量是(1/4)\*(1-p)+(3/4)\*p =(1 /4)+ p / 2。 因此，我们可以将小p估计为回答“是”的数量的两倍再减去1/2，即2((1/4)+ p / 2) - 1/2。

随机化是必不可少的; 更准确地说，无论所有当前或未来的辅助信息来源(包括其他数据库，研究，网站，在线社区，八卦，报纸，政府统计等)都可以使用的任何实用的隐私保障都需要随机化。这是从我们现在简单描述的一个简单的混合论点开始的。假设为了产生矛盾，我们有一个实用的确定性算法。实用性认为存在一个查询和两个数据库，在该查询下产生不同的输出。但一次更改一行，我们发现存在一对不同的数据库，只有一行的值不同，相同的查询产生不同的输出。对手知道正确的数据库是这两个几乎相同的数据库中的一个，但只是知道一个未知行中数据的值。

因此，我们需要讨论随机算法的输入和输出空间。 在整篇专著中，我们使用离散概率空间。 有时我们会将我们的算法描述为连续分布的采样，但这些算法应该始终以适当谨慎的方式离散化为有限精度(参见下面的备注2.1)。通常，具有域A和(离散)范围B的随机化算法将与一个从A到B上概率单纯形的映射（a mapping from A to the probability simplex over B，不会翻译，给出原文）相关联，记为Δ(B)：

**定义2.1**(概率单纯形 Probability Simplex)。 给定一个离散集B，其上的概率单纯形记为Δ(B)，定义为：

![2.1.png](https://i.loli.net/2018/05/28/5b0b655799e74.png)

 	↓ This block just for test Mathematical formula
 $$
 \sqrt{3x-1}+(1+x)^2
 $$

 $$h(\theta)=\sum_{j=0}^n \theta_jx_j$$

 &fnof;(x)=x+1

 &radic;5

30&deg;

z=z_l

\frac{d}{dx}e^{ax}=ae^{ax}\quad \sum_{i=1}^{n}{(X_i - \overline{X})^2}


 	↑ This block just for test Mathematical formula

<script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

**定义2.2**（随机算法）。 随机化算法M：具有域A和离散范围B的，其映射M：A→Δ(B)。在输入a∈A时，对每个b∈B，算法M以概率(M(a))<sub>b</sub>输出M(a)=b。算法M的概率空间在硬币翻转之上（The probability space is over the coin flips of the algorithm M.不会翻译，附上原文）。

我们将数据库x视为来自所有 χ 的记录集合。通过直方图表示数据库通常很方便：
x∈N<sup>|χ|</sup>，其中每个条目xi表示数据库x中元素的数量，其中i∈ χ （我们稍微滥用记号，用符号N表示包括零在内的所有非负整数的集合）。在这个表示中，两个数据库x和y之间自然度量的距离将是它们的ℓ1距离：

![2.3.png](https://i.loli.net/2018/05/28/5b0c03248f901.png)

两个数据库x和y之间的ℓ1距离是|| x-y ||<sub>1</sub>

请注意，|| x ||<sub>1</sub>是数据库x的大小(即它包含的记录的数量)的度量，并且|| x-y ||<sub>1</sub>是x和y之间有多少记录不同的度量。

数据库也可以由多行(X的元素)或甚至有序的行列表来表示，这里有集合的一种特殊情况，其中的行号成为元素名称的一部分。在这种情况下，数据库之间的距离通常通过汉明距离来衡量，即它们不同的行数。

但是，除非另有说明，否则我们将使用上述的直方图表示法。（但是请注意，即使直方图符号在数学上更方便，在实际实现中，多重集合表示通常会更加简洁）。

我们现在准备好正式定义差分隐私，这将直观地保证随机算法在类似的输入数据库上表现相近。

**定义2.4**(差分隐私)。.如果对所有的S⊆Range(M)和对于所有的x，y∈N|X使得‖x-y‖<sub>1</sub>≤1，那么具有域N|X|的随机化算法M满足(ε,δ)差分隐私：

![2.4.png](https://i.loli.net/2018/05/28/5b0c0558e0e84.png)

其中机制M的概率空间在硬币翻转之上 _（ the probability space is over the coin flips of the mechanism M. 不会翻译，附上原句）_。如果δ= 0，我们说M是ε-差分隐私。

通常我们感兴趣的是δ值小于数据库大小的任何多项式的倒数。特别当δ值大约为1 /‖x‖1时是非常危险的：它们通过发布少量数据库参与者的完整记录来允许“保护隐私” - 正是在第1章中讨论的“少数”哲学。

然而，即使δ可以忽略不计，（ε，0）-差分隐私与（ε，δ）-差分隐私之间也存在理论上的区别。 这其中的主要区别就是量化顺序的切换。（ε，0）-差分隐私确保了对于机制M（x）的每次运行，所观察到的输出（几乎）同样可能在每个相邻的数据库上同时被观察到。 相反，（ε，δ）-差分隐私表示，对于每一对相邻的数据库x，y，事后观察值M（x）极不可能在当数据库是x时比数据库是y时产生更多或更少。 然而，给定一个输出ξ〜M（x），有可能找到一个数据库y，使得ξ更有可能在y上产生，而不是在数据库为x时产生。 也就是说，分布M（y）中ξ的数量可能远大于其分布M（x）中的数量。

这数量

![1529219578(1).png](https://i.loli.net/2018/06/17/5b260a92e72f0.png)

对我们很重要; 我们称之为由观察ξ引起的隐私损失。这种损失可能是正值(当事件更可能发生在x而不是y时)或者可能是负面的(当事件更可能发生在y而不是x时)。 正如我们将在引理3.17中看到的那样，(ε，δ) –差分隐私确保了对于所有相邻的x，y，隐私损失的绝对值将以ε界定，其概率至少为1-δ。 与往常一样，概率空间位于机制M的硬币之上。_（As always, the probability space iss of the mechanism M.附原句，此句不会翻译 ）_

差分隐私不受后处理影响：数据分析师在没有关于私有数据库的额外知识的情况下，无法计算私有算法M输出的函数，并且无法使其不那么具有私密性。 也就是说，如果一种算法保护个人的隐私，那么无论是在正式定义下还是在任何直观的意义上，数据分析师不能增加隐私损失，只需坐在角落并考虑算法的输出。 形式上，具有（ε，δ）-差分隐私算法M的数据无关映射f的组成也是（ε，δ）差分隐私：

**命题2.1**(后处理)。 令M：N<sup>|X|</sup>→R是满足(ε，δ)-差分隐私的随机算法，f:R→R'是一个任意的随机映射。则f◦M：N<sup>|X|</sup> →R'满足(ε，δ) -差分隐私。

证明。 暂略，详见原著第19页。

从定义2.4立即可以看出，（ε，0）-差分隐私以直接的方式构成：两个（ε，0）-差分隐私机制的组合是（2ε，0）-差分隐私。更一般地说（定理3.16），“ε和δ增加”：对于1≤i≤k，第i个机制是（ε<sub>i</sub>，δ<sub>i</sub>）-差分隐私机制的组成是（Σ<sub>i</sub>ε<sub>i</sub>，Σ<sub>i</sub>δ<sub>i</sub>）-差分隐私。

(ε，0) –差分隐私的群体隐私机制也在定义2.4中立即出现，隐私保证的强度随群组的增大线性下降。_（with the strength of the privacy guarantee drops linearly with the size of the group.附原句）_

定理2.2。 对于所有的‖x-y‖<sub>1</sub>≤k和所有的S⊆Range（M），群体的大小为k，任何满足（ε，0）-差分隐私机制M都是（kε, 0）-差分隐私。

Pr[m(x)∈S] ≤exp(kε) Pr[m(y)∈S],

其中概率空间超过机制M的硬币翻转。_（where the probability space is over the coin flips of the mechanism M.附原句）_

例如，这涉及到包含多个家庭成员的调查中的隐私问题。

更一般地说，组合和群体隐私不是同一件事情，第3.5.2节（定理3.20）中改进的组合边界大大改善了k因子，但即使当δ= 0时,不能（也做不到）为群体隐私产生同样的收益。

### 2.3.1 差分隐私承诺什么

经济学观点。差分隐私有望保护个人免受因为他们的数据位于私人数据库x中所可能面临的任何额外损害，如果他们的数据未成为x的一部分，他们将不会面临这些损害。虽然一旦差分隐私机制M的结果M（x）被释放，个人可能确实面临伤害，但是差分隐私承诺伤害的概率不会因为他们选择参与而显着增加。这是一个非常实用的隐私定义，因为当一个人决定是否将她的数据包含在一个将以不同的隐私方式使用的数据库中时，她会正在考虑这样一种差异：她参与其中受到伤害的可能性，较之于她没有参与而受到伤害的可能性。她无法控制数据库的其余内容。考虑到差分隐私的承诺，从未来的伤害角度来看，她确信她应该几乎对是否参与而漠不关心。给予任何激励 - 从利他主义到金钱奖励 - 差分隐私可以说服她允许使用她的数据。这种直觉可以在实用主义理论意义上形式化，我们在这里简要描述。

考虑一个对所有可能的未来事件集合具有任意偏好的个体i，我们用A表示的。这些偏好表示为效用函数u<sub>i</sub>：A→R≥0， 并且我们说，在a∈A出现的情况下，个体i满足效应函数u<sub>i</sub>(a)∈A。_（we say that individual i experiences utility ui(a) in the event that a∈A comes to pass. 附原句）_ 假设x∈N|X| 是一个包含个体私人数据的集合，_（Suppose that x∈N|X| is a data-set containing individual is private data, ）_ 而M是一个ε-差分隐私算法。 假设y是一个与x相同的数据集，只是它不包含个体i的数据(特别是‖x-y‖<sub>1</sub>= 1)，以机制M的输出为条件，设f：Range (M)→Δ(A) 为 （任意）函数，它决定未来事件A的分布。通过保证差分隐私以及命题2.1保证的任意后处理的恢复能力，我们有：

![1529226919(1).png](https://i.loli.net/2018/06/17/5b2626c312dbb.png)

因此，通过承诺ε-差分隐私的保证，数据分析师可以向个人保证他的预期未来效用不会受到超过exp（ε）≈（1 +ε）因子的损害。请注意，该承诺独立于个人效用函数u<sub>i</sub>，并且同时适用于可能具有完全不同效用函数的多个人。

### 2.3.2 什么是差分隐私不承诺的

### 2.3.3 关于定义的最后评论

> <span style="color:orange"> To see more, please visit [<span style="color:blue">Homepage</span>](https://ShixiongMarryMe.github.io/). </span>

> <span style="color:orange"> Connect with me at <span style="color:blue"><shixiongmarryme@gmail.com></span>. </span>

__*欢迎纠正不妥之处，转载敬请注明出处*__
